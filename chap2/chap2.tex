\chapter[Related Work]{Related Work}
\label{chap:chap2}
\section{Sonification and Generative Art}

The question of mapping computational fluid dynamics data into sound belongs to the intersection of the domains of {\em sonification} and {\em generative art}. Sources vary in agreement on the definition of sonification. According to Hermann, sonification is ``the technique of rendering sound in response to data and interactions.'' \cite{hermann2011sonification} Kramer et al.~define it as ``the use of nonspeech audio to convey information.'' \cite{kramer2010sonification} We shall make a distinction between {\em scientific} sonification, which aims primarily toward conveying information clearly, and {\em musical sonification}, which aims primarily toward aesthetically useful generation of music. There are many possible strategies for sonification, including audification, parameter mapping sonification, and model-based sonification. \cite{hermann2011sonification} We shall expand upon the meaning of these terms in \S\cite{sec:background}.

Generative art is sometimes thought of in very general terms. For instance, Boden specifies eleven different categories of generative art: electronic art, computer art, computer-assisted art digital art, generative art, computer-generated art, evolutionary art, robot art, interactive art, computer-interactive art, and virtual reality art. \cite{boden2009generative}. In the text, however, we prefer a more narrow definition of generative art as art which has been created through the design and use of a computational system.

One of the main attractions of this compositional style is the possibility of novel discoveries that go beyond what the artist may otherwise have been able to conceive: ``The computer can allow a composer to write music that goes beyond that which she is already capable of.'' \cite{roads2015composing}

\subsection{Background}
\label{sec:background}
The use of natural processes as a technique in music composition has been well known for centuries, from the Greek's use of harmonic proportions in tuning to Mozart's dice music. The twentieth century saw an increased interest in formalized mathematical systems as part of musical composition. Composers and theorists such as Schillinger, Stockhausen, Xenakis, Cage, Lucier, Lewin, and many others explored different systematic ways of generating sonic art. In the twenty-first century, with the explosion of the idea of ``big data,'' music and sound has been generated from all sorts of data sets such as astronomical measurements, seismographs, web traffic, and more. Gradually, an important question emerged: is the composer focused primarily with the listener's musical experience, or is it the intent that the music inform the listener of features of the underlying data? Such a question touches the tip of the iceberg of many challenging philosophical questions, such as whether music can even have any external meaning, or the distinction between the artist's intention and the listener's response. While we shall only explore a few of these ideas in some detail, the interested reader can find more thorough discussions in \todo{citation}.

In the earlier forms of sonification, the data itself tended to be the most prominent feature. Indeed, sonification was viewed as an offshoot of data visualization. Thus, for example, the technique of audification, in which data values are mapped directly to sound pressure levels, by maintaining a literal connection between the data and the sound, serves as a direct form of sonification. Audification has been used in especially for natural phenomenon that generate time series, such as seismology, or stock market prices. Parameter mapping, by contrast, is more of a second-order technique in which one parameter of the data is mapped to a parameter of sound, such as pich, or volume. For example, a series of data representing temperature values might be mapped to pitch in such a way that higher temperature sounds as higher pitch, and vice versa. Although the data is not literally being interpreted as a waveform, the analogy of human perception still makes the connection between the data and sound tangible. Finally, more abstract forms of sonification, such as model-based techniques, in which a time-varying process is devised that connects the data and sound together, can strain the perceptual limits of the link between the data and the sound, although formally speaking, it still is present. Kramer proposes a ``semiotic'' spectrum from analogic to symbolic sonifications, with audification at the extreme analogic end as closest to the data, parameter mapping in the middle, and model-based techniques at the symbolic extreme.

\subsection{Model-Based Sonification}
\label{sec:modelbased}
As our particular research strategy resembles the category of model-based sonification the most closely, we review this technique in some detail.
According to Hermann, ``Model-Based Sonification is a sonification technique that takes a
particular look at how acoustic responses are generated in response to the userâ€™s actions, and
offers a framework to govern how these insights can be carried over to data sonification. As
a result, Model-Based Sonification demands the creation of processes that involve the data in
a systematic way, and that are capable of evolving in time to generate an acoustic signal.'' \cite{hermann2011sonification} The latter quality of evolving in time to generate an acoustic signal interests us the most, as the time evolution in such models is often governed systematically according to physical principles, making it an ideal candidate for a sonification of a physical process such as fluid dynamics. After exploring some fundamental ideas in human perception and modes of listening, Hermann concludes that a successful sonificaton should satisfy five properties, paraphrased thusly:
\begin{itemize}
	\item Ubiquity: Each interaction with data should produce a sound.
	\item Invariance of binding mechanism: The laws producing the sound from the data should not depend on the data itself, much in the same way that the
	laws of physics do not depend on the specific objects that they govern.
	\item Immediate response: Each interaction with the data should produce an immediate response in order to mirror as closely as possible interactions with objects in the real world
	\item Sonic variability: Sonifications should vary according to subtle changes in state and input.
	\item Information richness: Sonifications should be nontrivial.
\end{itemize}
Essentially, these properties gurantee that a sonification mimics interactions in the real world with data and sound. This ties in with a more analytical mode of listening---for instance, shaking a wrapped birthday present to try to determine its contents from the corresponding sound, rather than listening to the sound of the jostling present as a musical event.


\subsection{Aesthetics}
A continual dilemma in generative art is the conflict between the level of rigor of the underlying formal system and the human perception of its output. Some artists (e.g. Milton Babbitt) take the dogmatic position that the logic of the system trumps the general perception of the output. \cite{babbitt1958cares}  However, others such as K{\v{r}}enek have taken a more careful middle ground, arguing that the existence of an aesthetically coherent system of rules is no guarantee that an aesthetically coherent artistic result will perceptibly emerge: ``We cannot take the bare logical coherence of a musical `axiomatic' system as the sole criterion of its soundness! \dots The outstanding characteristic of music [is] its independence from the linguistic limitations of general logic.'' \cite{kvrenek1939music}